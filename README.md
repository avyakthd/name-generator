# Language Models
This repository is a work in progress, and would eventually be updated with code to create a small LM; based off Andrej Karpathy's `makemore`.
## Currently Available:
[Bigram-LM](Bigram_LM.ipynb) contains the `.ipynb` code to test and run the code. In case you wish to view the static HTML version, click [here](Bigram_LM.html).
## Upcoming:
- Expanding the context window from `2` characters to `3`, and generalising the code to accomodate `N-gram` implementations.   
- Using Multi-layer Perceptrons and fine-tuning them to improve the predictions- using the inbuilt loss-propagation, and manual back-propagation.   
- Implementing the Transformer Architecture, and expanding further on it.   
